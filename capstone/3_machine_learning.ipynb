{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### load libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load and transform\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ml\n",
    "#from sklearn import cross_validation\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "#from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from rank_metrics import ndcg_at_k\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# graphics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# make figures better:\n",
    "font = {'weight':'normal','size':20}\n",
    "plt.rc('font', **font)\n",
    "plt.rc('figure', figsize=(9.0, 6.0))\n",
    "plt.rc('xtick.major', pad=10) # xticks too close to border!\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#print(plt.style.available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unzip and load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_countries => rows: 10; columns: 7\n",
      "df_country_demographics => rows: 420; columns: 5\n",
      "df_user_sessions => rows: 10567737; columns: 6\n",
      "df_train => rows: 213451; columns: 16\n",
      "df_test => rows: 62096; columns: 15\n"
     ]
    }
   ],
   "source": [
    "# Dataset #1: Countries to visit\n",
    "zf = zipfile.ZipFile('data/countries.csv.zip')\n",
    "df_countries = pd.read_csv(zf.open('countries.csv'))\n",
    "print(\"df_countries => rows: %0.0f; columns: %0.0f\" % np.shape(df_countries))\n",
    "\n",
    "# Dataset #2: Compare demographic distributions within destination countries\n",
    "zf = zipfile.ZipFile('data/age_gender_bkts.csv.zip')\n",
    "df_country_demographics = pd.read_csv(zf.open('age_gender_bkts.csv'))\n",
    "print(\"df_country_demographics => rows: %0.0f; columns: %0.0f\" % np.shape(df_country_demographics))\n",
    "\n",
    "# Dataset #3: User interactions on airbnb website\n",
    "zf = zipfile.ZipFile('data/sessions.csv.zip')\n",
    "df_user_sessions = pd.read_csv(zf.open('sessions.csv'))\n",
    "print(\"df_user_sessions => rows: %0.0f; columns: %0.0f\" % np.shape(df_user_sessions ))\n",
    "\n",
    "# Dataset #4: Comparing test and training data to what has been provided as user data for 2015\n",
    "# train\n",
    "zf = zipfile.ZipFile('data/train_users_2.csv.zip')\n",
    "df_train = pd.read_csv(zf.open('train_users_2.csv'))\n",
    "print(\"df_train => rows: %0.0f; columns: %0.0f\" % np.shape(df_train))\n",
    "\n",
    "# test\n",
    "zf = zipfile.ZipFile('data/test_users.csv.zip')\n",
    "df_test = pd.read_csv(zf.open('test_users.csv'))\n",
    "print(\"df_test => rows: %0.0f; columns: %0.0f\" % np.shape(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine, transform and engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_users => rows: 275547; columns: 16\n"
     ]
    }
   ],
   "source": [
    "# concatenate train- and test users together in order to do all the changes on both datasets\n",
    "df_users = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "print(\"df_users => rows: %0.0f; columns: %0.0f\" % np.shape(df_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_users => observations: 275547; features: 167\n",
      "destination encoding:\n",
      "[(-1, 0), ('AU', 1), ('CA', 2), ('DE', 3), ('ES', 4), ('FR', 5), ('GB', 6), ('IT', 7), ('NDF', 8), ('NL', 9), ('PT', 10), ('US', 11), ('other', 12)]\n"
     ]
    }
   ],
   "source": [
    "### transformations ###\n",
    "\n",
    "# incorrectly populated ages\n",
    "av = df_users.age.values\n",
    "df_users['age'] = np.where(np.logical_and(av>1900, av<2015), 2015-av, av) # fix those with year of birth as age\n",
    "df_users['age'] = np.where(np.logical_or(av<14, av>100), np.nan, av) # set all ages deemed unlikely as null\n",
    "\n",
    "# handling nulls \n",
    "df_users.replace(\"-unknown-\", np.nan, inplace=True)\n",
    "df_users.fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "### feature engineering ###\n",
    "\n",
    "# date_account_created\n",
    "df_users['date_account_created'] = pd.to_datetime(df_users.date_account_created)\n",
    "df_users['year_account_created'] = df_users.date_account_created.dt.year\n",
    "df_users['month_account_created'] = df_users.date_account_created.dt.month\n",
    "df_users['week_account_created'] = df_users.date_account_created.dt.week\n",
    "df_users['weekday_account_created'] = df_users.date_account_created.dt.weekday\n",
    "df_users['day_account_created'] = df_users.date_account_created.dt.day\n",
    "\n",
    "# timestamp_first_active\n",
    "df_users['date_first_active'] = pd.to_datetime((df_users.timestamp_first_active // 1000000), format='%Y%m%d')\n",
    "df_users['year_first_active'] = df_users.date_first_active.dt.year\n",
    "df_users['month_first_active'] = df_users.date_first_active.dt.month\n",
    "df_users['week_first_active'] = df_users.date_first_active.dt.week\n",
    "df_users['weekday_first_active'] = df_users.date_first_active.dt.weekday\n",
    "df_users['day_first_active'] = df_users.date_first_active.dt.day\n",
    "\n",
    "# cleanup\n",
    "# date_first_booking isn't populated in the test set so this feature can't be used \n",
    "# and I'm done with the orignal date fields\n",
    "drop_list = ['date_account_created','timestamp_first_active','date_first_active','date_first_booking']\n",
    "df_users.drop(drop_list, axis=1, inplace=True)\n",
    "\n",
    "#One-hot-encoding features\n",
    "ohe_features = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "for f in ohe_features:\n",
    "    df_encodings = pd.get_dummies(df_users[f], prefix=f)\n",
    "    df_users = df_users.drop([f], axis=1)\n",
    "    df_users = pd.concat((df_users, df_encodings), axis=1)\n",
    "    \n",
    "    \n",
    "### check impact of changes ###\n",
    "print(\"df_users => observations: %0.0f; features: %0.0f\" % np.shape(df_users))\n",
    "\n",
    "\n",
    "### setup ml structure ###\n",
    "le = LabelEncoder()\n",
    "labels = df_users['country_destination'].values\n",
    "y = le.fit_transform(labels) \n",
    "features = df_users.drop(['id','country_destination'], axis=1)\n",
    "\n",
    "print(\"destination encoding:\")\n",
    "print(list(zip(le.classes_,range(0,len(y)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "$x' = x - x_{min} / x_{max} - x_{min}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/train split\n",
    "after the transfromations and feature engineering has been performed on the combination of the training and the test set, these two data sets are split out once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split train and test\n",
    "cutt_off = df_train.shape[0]\n",
    "X_train, X_test, y_train, y_test = features[:cutt_off], y[:cutt_off], features[cutt_off:], y[cutt_off:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Destination in Position 0: NDGG = 1.000\n",
      "Correct Destination in Position 1: NDGG = 0.631\n",
      "Correct Destination in Position 2: NDGG = 0.500\n",
      "Correct Destination in Position 3: NDGG = 0.431\n",
      "Correct Destination in Position 4: NDGG = 0.387\n"
     ]
    }
   ],
   "source": [
    "# Simulate NDCG scorer used by Kaggle competition\n",
    "def ndcg_wrapper(y_true,y_pred_proba):\n",
    "    Y = np.fliplr(y_pred_proba.argsort())\n",
    "      \n",
    "    R = []\n",
    "    NDCG = []\n",
    "    for i in range(0,y_true.size):\n",
    "        r = (Y[i,:]==y_true[i]).astype(int)\n",
    "        R.append(r)\n",
    "        NDCG.append(ndcg_at_k(r,5,method=1))\n",
    "    return np.mean(NDCG)\n",
    "\n",
    "ndcg_scorer = make_scorer(ndcg_wrapper, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(\"Correct Destination in Position %d: NDGG = %.3f\" % (i,ndcg_at_k([0]*i+[1],5,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\utils\\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'argsort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-92ddf17e906c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# any of the algorithms built beyond this one should at the very least improve on this attempt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mDummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDummyClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'prior'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdummy_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndcg_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NDCG score for Dummy Estimator: {0:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Miniconda\\lib\\site-packages\\sklearn\\metrics\\scorer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    122\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sign\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_factory_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-109-d4ba68f9d1a0>\u001b[0m in \u001b[0;36mndcg_wrapper\u001b[1;34m(y_true, y_pred_proba)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Simulate NDCG scorer used by Kaggle competition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mndcg_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfliplr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'argsort'"
     ]
    }
   ],
   "source": [
    "# any of the algorithms built beyond this one should at the very least improve on this attempt \n",
    "Dummy = DummyClassifier(strategy='prior').fit(X_train,y_train)\n",
    "dummy_score = ndcg_scorer(Dummy, X_test, y_test)\n",
    "\n",
    "print('NDCG score for Dummy Estimator: {0:.4f}'.format(dummy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_train_labels = pd.DataFrame(train_labels,columns = ['country_destination'])\n",
    "encoded_train_labels['new_code'] = np.where((encoded_train_labels.country_destination == 'US'), 1,0)\n",
    "encoded_train_labels = encoded_train_labels.new_code\n",
    "encoded_train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "        train_set, train_labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"training: %i, %i\" % (X_train.shape[0],y_train.shape[0])\n",
    "print \"test: %i, %i\" % (X_test.shape[0],y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV('l2',C=1.0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "Characteristics:\n",
    "* low bais\n",
    "* high variance\n",
    "* prone to overfitting\n",
    "\n",
    "Tuning Parameters:\n",
    "* number of trees\n",
    "* number of features to consider at each split\n",
    "* depth of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=200,n_jobs=-1,class_weight='balanced',oob_score=True)\n",
    "CV_score = cross_val_score(RF,X,y,scoring=ndcg_scorer, cv=5, verbose=2)\n",
    "\n",
    "print('CV scores = ',CV_score)\n",
    "print('Mean CV score = ', np.mean(CV_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n",
    "                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \n",
    "xgb.fit(X, y)\n",
    "y_pred = xgb.predict_proba(X_test)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more features \n",
    "In order to see whether adding session data makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sessions\n",
    "sessions.rename(columns = {'user_id': 'id'}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
