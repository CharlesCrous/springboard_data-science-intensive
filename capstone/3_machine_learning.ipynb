{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### load libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# make figures better:\n",
    "font = {'weight':'normal','size':20}\n",
    "plt.rc('font', **font)\n",
    "plt.rc('figure', figsize=(9.0, 6.0))\n",
    "plt.rc('xtick.major', pad=10) # xticks too close to border!\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#print(plt.style.available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anchor point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unzip and load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_countries => rows: 10; columns: 7\n",
      "df_country_demographics => rows: 420; columns: 5\n",
      "df_user_sessions => rows: 10567737; columns: 6\n",
      "df_train => rows: 213451; columns: 16\n",
      "df_test => rows: 62096; columns: 15\n"
     ]
    }
   ],
   "source": [
    "# Dataset #1: Countries to visit\n",
    "zf = zipfile.ZipFile('data/countries.csv.zip')\n",
    "df_countries = pd.read_csv(zf.open('countries.csv'))\n",
    "print(\"df_countries => rows: %0.0f; columns: %0.0f\" % np.shape(df_countries))\n",
    "\n",
    "# Dataset #2: Compare demographic distributions within destination countries\n",
    "zf = zipfile.ZipFile('data/age_gender_bkts.csv.zip')\n",
    "df_country_demographics = pd.read_csv(zf.open('age_gender_bkts.csv'))\n",
    "print(\"df_country_demographics => rows: %0.0f; columns: %0.0f\" % np.shape(df_country_demographics))\n",
    "\n",
    "# Dataset #3: User interactions on airbnb website\n",
    "zf = zipfile.ZipFile('data/sessions.csv.zip')\n",
    "df_user_sessions = pd.read_csv(zf.open('sessions.csv'))\n",
    "print(\"df_user_sessions => rows: %0.0f; columns: %0.0f\" % np.shape(df_user_sessions ))\n",
    "\n",
    "# Dataset #4: Comparing test and training data to what has been provided as user data for 2015\n",
    "# train\n",
    "zf = zipfile.ZipFile('data/train_users_2.csv.zip')\n",
    "df_train = pd.read_csv(zf.open('train_users_2.csv'))\n",
    "print(\"df_train => rows: %0.0f; columns: %0.0f\" % np.shape(df_train))\n",
    "\n",
    "# test\n",
    "zf = zipfile.ZipFile('data/test_users.csv.zip')\n",
    "df_test = pd.read_csv(zf.open('test_users.csv'))\n",
    "print(\"df_test => rows: %0.0f; columns: %0.0f\" % np.shape(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine, transform and engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_users => rows: 275547; columns: 16\n"
     ]
    }
   ],
   "source": [
    "# concatenate train- and test users together in order to do all the changes on both datasets\n",
    "df_users = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "print(\"df_users => rows: %0.0f; columns: %0.0f\" % np.shape(df_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_users => rows: 275547; columns: 23\n"
     ]
    }
   ],
   "source": [
    "### transformations ###\n",
    "\n",
    "# incorrectly populated ages\n",
    "av = df_users.age.values\n",
    "df_users['age'] = np.where(np.logical_and(av>1900, av<2015), 2015-av, av) # fix those with year of birth as age\n",
    "df_users['age'] = np.where(np.logical_or(av<14, av>100), np.nan, av) # set all ages deemed unlikely as null\n",
    "\n",
    "# handling nulls \n",
    "df_users.replace(\"-unknown-\", np.nan, inplace=True)\n",
    "df_users.fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "### feature engineering ###\n",
    "\n",
    "# date_account_created\n",
    "df_users['date_account_created'] = pd.to_datetime(df_users.date_account_created)\n",
    "df_users['year_account_created'] = df_users.date_account_created.dt.year\n",
    "df_users['month_account_created'] = df_users.date_account_created.dt.month\n",
    "df_users['week_account_created'] = df_users.date_account_created.dt.week\n",
    "df_users['weekday_account_created'] = df_users.date_account_created.dt.weekday\n",
    "df_users['day_account_created'] = df_users.date_account_created.dt.day\n",
    "\n",
    "# timestamp_first_active\n",
    "df_users['date_first_active'] = pd.to_datetime((df_users.timestamp_first_active // 1000000), format='%Y%m%d')\n",
    "df_users['year_first_active'] = df_users.date_first_active.dt.year\n",
    "df_users['month_first_active'] = df_users.date_first_active.dt.month\n",
    "df_users['week_first_active'] = df_users.date_first_active.dt.week\n",
    "df_users['weekday_first_active'] = df_users.date_first_active.dt.weekday\n",
    "df_users['day_first_active'] = df_users.date_first_active.dt.day\n",
    "\n",
    "# cleanup\n",
    "# date_first_booking isn't populated in the test set so this feature can't be used \n",
    "# and I'm done with the orignal date fields\n",
    "drop_list = ['date_account_created','timestamp_first_active','date_first_active','date_first_booking']\n",
    "df_users.drop(drop_list, axis=1, inplace=True)\n",
    "\n",
    "### check impact of changes ###\n",
    "print(\"df_users => rows: %0.0f; columns: %0.0f\" % np.shape(df_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/train split\n",
    "after the transfromations and feature engineering has been performed on the combination of the training and the test set, these two data sets are split out once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup ml structure\n",
    "labels = df_users['country_destination'].values\n",
    "features = df_users.drop(['id','country_destination'], axis=1)\n",
    "\n",
    "# split train and test\n",
    "X_train, X_test, y_train, y_test = features[len(df_train):], labels[len(df_train):], features[-len(df_test):], labels[-len(df_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "Characteristics:\n",
    "* low bais\n",
    "* high variance\n",
    "* prone to overfitting\n",
    "\n",
    "Tuning Parameters:\n",
    "* number of trees\n",
    "* number of features to consider at each split\n",
    "* depth of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "scikit-learn uses an optimised version of the CART algorithm. CART (Classification and Regression Trees) supports both categorical and numerical target variables (regression) and does not compute rule sets. CART constructs binary trees using the feature and threshold that yield the largest information gain at each node.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = df_users\n",
    "# setup ml structure\n",
    "labels = dataframe['country_destination'].values\n",
    "\n",
    "# date_account_created\n",
    "dataframe['date_account_created'] = pd.to_datetime(dataframe.date_account_created)\n",
    "dataframe['creation_year'] = dataframe.date_account_created.dt.year\n",
    "dataframe['creation_month'] = dataframe.date_account_created.dt.month\n",
    "dataframe['creation_day'] = dataframe.date_account_created.dt.day\n",
    "\n",
    "# timestamp_first_active\n",
    "dataframe['date_first_active'] = pd.to_datetime((dataframe.timestamp_first_active // 1000000), format='%Y%m%d')\n",
    "dataframe['active_year'] = dataframe.date_first_active.dt.year\n",
    "dataframe['active_month'] = dataframe.date_first_active.dt.month\n",
    "dataframe['active_day'] = dataframe.date_first_active.dt.day\n",
    "\n",
    "# cleanup\n",
    "# date_first_booking isn't populated in the test set so this feature can't be used\n",
    "features = dataframe.drop(['id','country_destination','date_account_created','timestamp_first_active','date_first_active','date_first_booking'], axis=1)\n",
    "features.replace(\"-unknown-\", np.nan, inplace = True)\n",
    "features = features.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = features[0:len(df_train)], labels[0:len(df_train)], features[len(df_test):], labels[len(df_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape,  y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to do some encoding before using fit. As it was told fit() does not accept Strings but you solve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encoding\n",
    "encoded_features_train = pd.get_dummies(features_train)\n",
    "encoded_features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign\n",
    "X_train, y_train = encoded_features_train, labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "regr_1 = DecisionTreeClassifier(max_depth=2)\n",
    "regr_2 = DecisionTreeClassifier(max_depth=5)\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_2 = regr_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.scatter(X_train, y_train, c=\"k\", label=\"data\")\n",
    "plt.plot(X_test, y_1, c=\"g\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_2, c=\"r\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_features = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train/test dataset 70/30 split \n",
    "X, y, feature_names, target_name = encoded_features, target, list(encoded_features),list(target)\n",
    "\n",
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "$x' = x - x_{min} / x_{max} - x_{min}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source: https://www.kaggle.com/davidgasquez/airbnb-recruiting-new-user-bookings/ndcg-scorer/code\n",
    "\n",
    "\"\"\"Metrics to compute the model performance.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    \"\"\"Discounted cumulative gain (DCG) at rank K.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array, shape = [n_samples, n_classes]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\n",
    "\n",
    "    Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\n",
    "    recommendation system based on the graded relevance of the recommended\n",
    "    entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\n",
    "    ranking of the entities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth : array, shape = [n_samples]\n",
    "        Ground truth (true labels represended as integers).\n",
    "    predictions : array, shape = [n_samples, n_classes]\n",
    "        Predicted probabilities.\n",
    "    k : int\n",
    "        Rank.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> ground_truth = [1, 0, 2]\n",
    "    >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    1.0\n",
    "    >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    0.6666666666\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    T = lb.fit_transform(ground_truth)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#Loading data\n",
    "df_train = pd.read_csv('../input/train_users.csv')\n",
    "df_test = pd.read_csv('../input/test_users.csv')\n",
    "labels = df_train['country_destination'].values\n",
    "df_train = df_train.drop(['country_destination'], axis=1)\n",
    "id_test = df_test['id']\n",
    "piv_train = df_train.shape[0]\n",
    "\n",
    "#Creating a DataFrame with train+test data\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "#Removing id and date_first_booking\n",
    "df_all = df_all.drop(['id', 'date_first_booking'], axis=1)\n",
    "#Filling nan\n",
    "df_all = df_all.fillna(-1)\n",
    "\n",
    "#####Feature engineering#######\n",
    "#date_account_created\n",
    "dac = np.vstack(df_all.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\n",
    "df_all['dac_year'] = dac[:,0]\n",
    "df_all['dac_month'] = dac[:,1]\n",
    "df_all['dac_day'] = dac[:,2]\n",
    "df_all = df_all.drop(['date_account_created'], axis=1)\n",
    "\n",
    "#timestamp_first_active\n",
    "tfa = np.vstack(df_all.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)\n",
    "df_all['tfa_year'] = tfa[:,0]\n",
    "df_all['tfa_month'] = tfa[:,1]\n",
    "df_all['tfa_day'] = tfa[:,2]\n",
    "df_all = df_all.drop(['timestamp_first_active'], axis=1)\n",
    "\n",
    "#Age\n",
    "av = df_all.age.values\n",
    "df_all['age'] = np.where(np.logical_or(av<14, av>100), -1, av)\n",
    "\n",
    "#One-hot-encoding features\n",
    "ohe_feats = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "for f in ohe_feats:\n",
    "    df_all_dummy = pd.get_dummies(df_all[f], prefix=f)\n",
    "    df_all = df_all.drop([f], axis=1)\n",
    "    df_all = pd.concat((df_all, df_all_dummy), axis=1)\n",
    "\n",
    "#Splitting train and test\n",
    "vals = df_all.values\n",
    "X = vals[:piv_train]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)   \n",
    "X_test = vals[piv_train:]\n",
    "\n",
    "#Classifier\n",
    "xgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n",
    "                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \n",
    "xgb.fit(X, y)\n",
    "y_pred = xgb.predict_proba(X_test)  \n",
    "\n",
    "#Taking the 5 classes with highest probabilities\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n",
    "\n",
    "#Generate submission\n",
    "sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more features \n",
    "In order to see whether adding session data makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sessions\n",
    "sessions.rename(columns = {'user_id': 'id'}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
