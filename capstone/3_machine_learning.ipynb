{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### load libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load and transform\n",
    "from time import time\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ml\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics, feature_selection\n",
    "from rank_metrics import ndcg_at_k\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# graphics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# make figures better:\n",
    "font = {'weight':'normal','size':20}\n",
    "plt.rc('font', **font)\n",
    "plt.rc('figure', figsize=(9.0, 6.0))\n",
    "plt.rc('xtick.major', pad=10) # xticks too close to border!\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#print(plt.style.available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unzip and load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_countries => rows: 10; columns: 7\n",
      "df_country_demographics => rows: 420; columns: 5\n",
      "df_user_sessions => rows: 10567737; columns: 6\n",
      "df_train => rows: 213451; columns: 16\n",
      "df_test => rows: 62096; columns: 15\n"
     ]
    }
   ],
   "source": [
    "# Dataset #1: Countries to visit\n",
    "zf = zipfile.ZipFile('data/countries.csv.zip')\n",
    "df_countries = pd.read_csv(zf.open('countries.csv'))\n",
    "print(\"df_countries => rows: %0.0f; columns: %0.0f\" % np.shape(df_countries))\n",
    "\n",
    "# Dataset #2: Compare demographic distributions within destination countries\n",
    "zf = zipfile.ZipFile('data/age_gender_bkts.csv.zip')\n",
    "df_country_demographics = pd.read_csv(zf.open('age_gender_bkts.csv'))\n",
    "print(\"df_country_demographics => rows: %0.0f; columns: %0.0f\" % np.shape(df_country_demographics))\n",
    "\n",
    "# Dataset #3: User interactions on airbnb website\n",
    "zf = zipfile.ZipFile('data/sessions.csv.zip')\n",
    "df_user_sessions = pd.read_csv(zf.open('sessions.csv'))\n",
    "print(\"df_user_sessions => rows: %0.0f; columns: %0.0f\" % np.shape(df_user_sessions ))\n",
    "\n",
    "# Dataset #4: Comparing test and training data to what has been provided as user data for 2015\n",
    "# train\n",
    "zf = zipfile.ZipFile('data/train_users_2.csv.zip')\n",
    "df_train = pd.read_csv(zf.open('train_users_2.csv'))\n",
    "print(\"df_train => rows: %0.0f; columns: %0.0f\" % np.shape(df_train))\n",
    "\n",
    "# test\n",
    "zf = zipfile.ZipFile('data/test_users.csv.zip')\n",
    "df_test = pd.read_csv(zf.open('test_users.csv'))\n",
    "print(\"df_test => rows: %0.0f; columns: %0.0f\" % np.shape(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine, transform and engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_users => rows: 275547; columns: 16\n"
     ]
    }
   ],
   "source": [
    "# concatenate train- and test users together in order to do all the changes on both datasets\n",
    "df_users = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "print(\"df_users => rows: %0.0f; columns: %0.0f\" % np.shape(df_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temporary -- use only a somple for testing purposes\n",
    "#sample = np.random.choice(df_users.index.values, 1000, replace=False)\n",
    "#df_users = df_users.ix[sample] \n",
    "#print(\"df_users => rows: %0.0f; columns: %0.0f\" % np.shape(df_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_users => observations: 275547; features: 167\n",
      "destination encoding:\n",
      "[(0, 0), ('AU', 1), ('CA', 2), ('DE', 3), ('ES', 4), ('FR', 5), ('GB', 6), ('IT', 7), ('NDF', 8), ('NL', 9), ('PT', 10), ('US', 11), ('other', 12)]\n"
     ]
    }
   ],
   "source": [
    "### transformations ###\n",
    "\n",
    "# incorrectly populated ages\n",
    "av = df_users.age.values\n",
    "df_users['age'] = np.where(np.logical_and(av>1900, av<2015), 2015-av, av) # fix those with year of birth as age\n",
    "df_users['age'] = np.where(np.logical_or(av<14, av>100), np.nan, av) # set all ages deemed unlikely as null\n",
    "mean_age = av.mean()\n",
    "df_users['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "# handling nulls \n",
    "df_users.replace(\"-unknown-\", np.nan, inplace=True)\n",
    "df_users.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "### feature engineering ###\n",
    "\n",
    "# date_account_created\n",
    "df_users['date_account_created'] = pd.to_datetime(df_users.date_account_created)\n",
    "df_users['year_account_created'] = df_users.date_account_created.dt.year\n",
    "df_users['month_account_created'] = df_users.date_account_created.dt.month\n",
    "df_users['week_account_created'] = df_users.date_account_created.dt.week\n",
    "df_users['weekday_account_created'] = df_users.date_account_created.dt.weekday\n",
    "df_users['day_account_created'] = df_users.date_account_created.dt.day\n",
    "\n",
    "# timestamp_first_active\n",
    "df_users['date_first_active'] = pd.to_datetime((df_users.timestamp_first_active // 1000000), format='%Y%m%d')\n",
    "df_users['year_first_active'] = df_users.date_first_active.dt.year\n",
    "df_users['month_first_active'] = df_users.date_first_active.dt.month\n",
    "df_users['week_first_active'] = df_users.date_first_active.dt.week\n",
    "df_users['weekday_first_active'] = df_users.date_first_active.dt.weekday\n",
    "df_users['day_first_active'] = df_users.date_first_active.dt.day\n",
    "\n",
    "# cleanup\n",
    "# date_first_booking isn't populated in the test set so this feature can't be used \n",
    "# and I'm done with the orignal date fields\n",
    "drop_list = ['date_account_created','timestamp_first_active','date_first_active','date_first_booking']\n",
    "df_users.drop(drop_list, axis=1, inplace=True)\n",
    "\n",
    "# One-hot-encoding features\n",
    "ohe_features = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "for f in ohe_features:\n",
    "    df_encodings = pd.get_dummies(df_users[f], prefix=f)\n",
    "    df_users = df_users.drop([f], axis=1)\n",
    "    df_users = pd.concat((df_users, df_encodings), axis=1)\n",
    "    \n",
    "    \n",
    "### check impact of changes ###\n",
    "print(\"df_users => observations: %0.0f; features: %0.0f\" % np.shape(df_users))\n",
    "\n",
    "\n",
    "### setup ml structure ###\n",
    "le = LabelEncoder()\n",
    "labels = df_users['country_destination'].values\n",
    "y = le.fit_transform(labels) \n",
    "features = df_users.drop(['id','country_destination'], axis=1)\n",
    "\n",
    "print(\"destination encoding:\")\n",
    "print(list(zip(le.classes_,range(0,len(y)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Destination in Position 1: NDGG = 1.000\n",
      "Correct Destination in Position 2: NDGG = 0.631\n",
      "Correct Destination in Position 3: NDGG = 0.500\n",
      "Correct Destination in Position 4: NDGG = 0.431\n",
      "Correct Destination in Position 5: NDGG = 0.387\n"
     ]
    }
   ],
   "source": [
    "# Simulate NDCG scorer used by Kaggle competition\n",
    "def ndcg_wrapper(y_true,y_pred_proba):\n",
    "    Y = np.fliplr(y_pred_proba.argsort())\n",
    "      \n",
    "    R = []\n",
    "    NDCG = []\n",
    "    for i in range(0,y_true.size):\n",
    "        r = (Y[i,:]==y_true[i]).astype(int)\n",
    "        R.append(r)\n",
    "        NDCG.append(ndcg_at_k(r,5,method=1))\n",
    "    return np.mean(NDCG)\n",
    "\n",
    "ndcg_scorer = metrics.make_scorer(ndcg_wrapper, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "# output example\n",
    "for i in range(0,5):\n",
    "    print(\"Correct Destination in Position %d: NDGG = %.3f\" % (i+1,ndcg_at_k([0]*i+[1],5,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG score for Dummy Estimator: 0.7303\n"
     ]
    }
   ],
   "source": [
    "# any of the algorithms built beyond this one should at the very least improve on this attempt \n",
    "Dummy = DummyClassifier(strategy='prior').fit(features, y)\n",
    "dummy_score = ndcg_scorer(Dummy, features, y)\n",
    "\n",
    "print('NDCG score for Dummy Estimator: {0:.4f}'.format(dummy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "First attempt: reduce problem to a binary analysis\n",
    "* testing for NDF vs not-NDF gave me a lower score than the dummy classifier\n",
    "    * prediction on training data: 0.692\n",
    "    * prediction on test data: 0.693\n",
    "  \n",
    "| classification_report | precision | recall | f1-score | support\n",
    "| :- | -- | -- | -- | -- |\n",
    "| Non-NDF | 0.71 | 0.76 | 0.73 | 45490\n",
    "| NDF | 0.67 | 0.61 | 0.64 | 37175\n",
    "| avg / total | 0.69 | 0.69 | 0.69 | 82665\n",
    "\n",
    "| Confusion_matrix | \n",
    "| :- | -- \n",
    "| 34502 | 10988 \n",
    "| 14399 | 22776 \n",
    "\n",
    "* testing for US vs non-US actually improved the calssification performance\n",
    "    * prediction on training data: 0.776\n",
    "    * prediction on test data: 0.771\n",
    "  \n",
    "| classification_report | precision | recall | f1-score | support\n",
    "| :- | -- | -- | -- | -- |\n",
    "| Non-US | 0.78 | 0.99 | 0.87 | 63664\n",
    "| US | 0.52 | 0.04 | 0.08 | 19001\n",
    "| avg / total | 0.72 | 0.77 | 0.69 | 82665\n",
    "\n",
    "| Confusion_matrix | \n",
    "| :- | -- \n",
    "| 62933 | 731 \n",
    "| 18219 | 782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275547L,)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where the country is indicated as 'NDF'==8, 'US'=11\n",
    "y_log  = np.where(y==11, 1, 0)\n",
    "y_log.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/train split\n",
    "after the transfromations and feature engineering has been performed on the combination of the training and the test set, these two data sets are split out once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, y_log, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Required by Logistic Regression\n",
    "\n",
    "$x' = x - x_{min} / x_{max} - x_{min}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 0.0954876538575 1.0 0.0 0.224878423077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train = MinMaxScaler().fit_transform(X_train)\n",
    "y_train = MinMaxScaler().fit_transform(y_train)\n",
    "X_test = MinMaxScaler().fit_transform(X_test)\n",
    "y_test = MinMaxScaler().fit_transform(y_test)\n",
    "\n",
    "print np.max(X_train), np.min(X_train), np.mean(X_train), np.max(y_train), np.min(y_train), np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier\n",
      "done in 94.408s\n",
      "[[  7.46369048e-01  -6.66137154e-01  -1.99638199e-01  -2.05718392e-01\n",
      "   -9.33634112e-03  -1.59563979e-02  -5.34728381e-01  -1.99667241e-01\n",
      "   -2.06819392e-01  -9.19315308e-03  -1.65536566e-02  -4.22925743e-01\n",
      "    2.21830133e-01   1.93287128e-01   7.78662536e-03   2.86698511e-01\n",
      "   -2.31976449e-01  -5.36593432e-02  -1.08457469e-03  -1.08052207e-01\n",
      "   -1.18876333e-01   3.25684139e-02   2.09642033e-01  -2.03404153e-04\n",
      "   -6.05683329e-03  -2.92366622e-03  -2.02595803e-02   1.77077291e-04\n",
      "    1.12077960e-01  -1.79480170e-04  -7.95900371e-04  -2.25237037e-03\n",
      "   -1.89038485e-03  -2.94470175e-03  -8.96548009e-02   1.75787228e-01\n",
      "   -1.76184906e-01  -7.01860268e-05   5.90597179e-04  -1.84075927e-03\n",
      "    7.30574543e-04   2.44048775e-03  -2.33982923e-03   1.43743116e-01\n",
      "   -2.82723445e-02   1.02101976e-03  -2.70270058e-02  -2.66028582e-04\n",
      "   -9.21821931e-04  -1.58778402e-03   1.87339310e-04  -3.56703769e-02\n",
      "   -4.30031490e-03  -5.87147350e-03  -2.01457040e-03   2.35531990e-03\n",
      "   -4.89620613e-03  -1.09892458e-02  -1.71761274e-02  -6.61465314e-04\n",
      "   -1.40325367e-03  -2.09536505e-03  -3.68615238e-03   1.46828814e-01\n",
      "   -1.93688079e-01   4.89039628e-02   1.94022824e-02  -2.53917568e-02\n",
      "    5.90021334e-02  -5.19486840e-04  -5.45597262e-02  -4.15175266e-04\n",
      "   -5.47801824e-02   4.89700251e-02  -1.56755324e-04   5.18276290e-02\n",
      "   -1.22617775e-02  -1.01545694e-01  -2.30297563e-02  -2.47266834e-02\n",
      "   -2.39417547e-02  -1.62505622e-02   7.85490466e-04   1.62988032e-01\n",
      "    6.60896260e-03  -1.49752425e-02  -8.57082889e-04   2.30902614e-03\n",
      "   -5.70355935e-04  -2.27282465e-02   1.30304957e-02  -3.83511693e-03\n",
      "   -4.23757781e-03  -9.25652157e-02  -6.89106709e-02   2.29347001e-02\n",
      "    1.56289776e-01  -1.25187180e-01   6.04482830e-03   1.94223594e-01\n",
      "   -7.51030985e-02  -2.28410413e-01  -1.77465077e-02   2.36881648e-02\n",
      "    2.21989907e-01   8.33371612e-03  -5.44512392e-03   6.73056016e-02\n",
      "    4.91332824e-02  -1.18870484e-01  -1.66184518e-01  -1.12694181e-02\n",
      "   -1.65314554e-02   1.25386094e-03  -1.79240198e-04  -7.65187757e-04\n",
      "   -8.31058837e-04   1.69513319e-03   1.86825737e-01  -7.49871955e-02\n",
      "    6.31234534e-03  -6.25499748e-04  -3.59673800e-04   0.00000000e+00\n",
      "    7.36640040e-04  -3.22284284e-04  -7.71794844e-05   1.57490279e-01\n",
      "   -3.18372738e-04  -1.67980489e-04  -1.28536716e-04   0.00000000e+00\n",
      "   -3.35656786e-02  -5.43888895e-03  -8.86830799e-05   6.54371726e-04\n",
      "    6.06639471e-04  -2.49544465e-04   9.81807902e-04   2.22302104e-03\n",
      "   -4.68303287e-02   3.31762148e-06   0.00000000e+00   0.00000000e+00\n",
      "   -3.93527032e-04  -4.60886354e-03   7.08967768e-04  -2.04590031e-04\n",
      "    0.00000000e+00  -2.52826985e-04   2.64243825e-04  -4.43133485e-04\n",
      "   -1.01203362e-03   2.70075298e-03  -6.29032238e-04   4.79942146e-03\n",
      "    5.07649957e-05   6.24144469e-04  -8.77638955e-04   0.00000000e+00\n",
      "    6.88021658e-04   3.85690237e-04   0.00000000e+00  -1.82803231e-03\n",
      "    1.43385595e-04]]\n",
      "[-0.59448799]\n"
     ]
    }
   ],
   "source": [
    "# create the linear model classifier\n",
    "clf = LogisticRegressionCV()\n",
    "# fit (train) the classifier\n",
    "t0 = time()\n",
    "print(\"training classifier\")\n",
    "clf.fit(X_train, y_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "# print learned coeficients\n",
    "print clf.coef_\n",
    "print clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction...\n",
      "prediction on training data: 0.776\n",
      "done in 0.141s\n",
      "prediction...\n",
      "prediction on test data: 0.771\n",
      "done in 0.062s\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction...\")\n",
    "t0 = time()\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(\"prediction on training data: %0.3f\" % clf.score(X_train, y_train))\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "print(\"prediction...\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"prediction on test data: %0.3f\" % clf.score(X_test, y_test))\n",
    "print \"done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87     63664\n",
      "        1.0       0.52      0.04      0.08     19001\n",
      "\n",
      "avg / total       0.72      0.77      0.69     82665\n",
      "\n",
      "[[62935   729]\n",
      " [18223   778]]\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(y_test, y_pred)\n",
    "print metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Selection\n",
    "Select only the top 20% most important features using chi${^2}$ test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192882, 165)\n",
      "(192882L, 33L)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAF1CAYAAAAk8BgwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19b966a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=20)\n",
    "X_train_fs = fs.fit_transform(X_train, y_train)\n",
    "#FeatureScores = pd.Series(index=X_train_fs.columns,data=X_train_fs.scores_).sort_values(ascending=False)\n",
    "print X_train.shape\n",
    "print X_train_fs.shape\n",
    "FeatureScores = pd.Series(index=features.columns, data=fs.scores_).sort_values(ascending=True)\n",
    "FeatureScores[:10].plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/train split\n",
    "after the transfromations and feature engineering has been performed on the combination of the training and the test set, these two data sets are split out once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split train and test\n",
    "#cutt_off = df_train.shape[0]\n",
    "#X_train, X_test, y_train, y_test = features[:cutt_off], features[cutt_off:], np.array(y[:cutt_off]),  np.array(y[cutt_off:])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, y.reshape(-1, 1), test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_true=True, show_confussion_matric=True):\n",
    "    y_pred = clf.predict(X)\n",
    "    if show_accuracy:\n",
    "        print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\"\n",
    "    if show_classification_true:   \n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y, y_pred),\"\\n\"\n",
    "    if show_confussion_matric:    \n",
    "        print \"Confussion matrix\"\n",
    "        print metrics.confusion_matrix(y, y_pred),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.091s\n",
      "Accuracy:0.965 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     43529\n",
      "          1       0.96      0.95      0.95       375\n",
      "          2       0.92      0.93      0.92      1006\n",
      "          3       0.96      0.95      0.95       745\n",
      "          4       0.92      0.93      0.93      1598\n",
      "          5       0.93      0.93      0.93      3539\n",
      "          6       0.93      0.93      0.93      1591\n",
      "          7       0.93      0.90      0.92      1978\n",
      "          8       0.94      0.99      0.96     87368\n",
      "          9       0.98      0.90      0.94       518\n",
      "         10       0.97      0.86      0.91       154\n",
      "         11       0.99      0.90      0.94     43375\n",
      "         12       1.00      0.86      0.92      7106\n",
      "\n",
      "avg / total       0.97      0.96      0.96    192882\n",
      "\n",
      "\n",
      "Confussion matrix\n",
      "[[43529     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0   355     0     0     0     0     0     0    19     0     0     1\n",
      "      0]\n",
      " [    0     0   932     0     0     0     1     0    70     0     0     2\n",
      "      1]\n",
      " [    0     0     1   705     0     0     0     0    37     0     0     2\n",
      "      0]\n",
      " [    0     0     4     0  1489     0     0     0   102     0     0     3\n",
      "      0]\n",
      " [    0     2     1     0     4  3298     1     0   224     0     0     8\n",
      "      1]\n",
      " [    0     1     3     1     0     2  1477     0   101     0     0     6\n",
      "      0]\n",
      " [    0     0     2     1     4     5     5  1789   163     0     0     9\n",
      "      0]\n",
      " [    0     8    48    15    72   140    66    80 86714     0     0   217\n",
      "      8]\n",
      " [    0     0     1     0     0     3     0     1    48   464     0     1\n",
      "      0]\n",
      " [    0     0     0     0     0     0     2     0    17     0   132     3\n",
      "      0]\n",
      " [    0     3    15    13    39    68    30    44  4064     8     3 39085\n",
      "      3]\n",
      " [    0     0     7     3     7    20     3    12   831     2     1   137\n",
      "   6083]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "t0 = time()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "measure_performance(X_train, y_train, dt, show_accuracy=True, show_classification_true=True, show_confussion_matric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.123s\n",
      "Accuracy:0.617 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     18567\n",
      "          1       0.02      0.02      0.02       164\n",
      "          2       0.01      0.01      0.01       422\n",
      "          3       0.01      0.01      0.01       316\n",
      "          4       0.02      0.02      0.02       651\n",
      "          5       0.03      0.04      0.04      1484\n",
      "          6       0.02      0.02      0.02       733\n",
      "          7       0.02      0.02      0.02       857\n",
      "          8       0.66      0.68      0.67     37175\n",
      "          9       0.01      0.01      0.01       244\n",
      "         10       0.00      0.00      0.00        63\n",
      "         11       0.39      0.35      0.37     19001\n",
      "         12       0.06      0.06      0.06      2988\n",
      "\n",
      "avg / total       0.62      0.62      0.62     82665\n",
      "\n",
      "[[18567     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     3     5     1     4     8     1     3    70     1     1    57\n",
      "     10]\n",
      " [    0     0     5     3     9    13     2     7   207     2     0   151\n",
      "     23]\n",
      " [    0     2     3     2     6     9     8     6   150     2     0   114\n",
      "     14]\n",
      " [    0     3     7     8    14    26    13    16   291     6     0   220\n",
      "     47]\n",
      " [    0     4    21    13    26    57    27    31   694     9     0   525\n",
      "     77]\n",
      " [    0     1     6     6    15    30    16    15   353     4     0   246\n",
      "     41]\n",
      " [    0     2    10     2    23    23    22    20   423     4     0   266\n",
      "     62]\n",
      " [    0    88   223   177   379   831   402   486 25414   116    32  7686\n",
      "   1341]\n",
      " [    0     2     2     1     1     6     3     6   133     2     0    70\n",
      "     18]\n",
      " [    0     0     1     2     1     2     2     1    26     0     0    22\n",
      "      6]\n",
      " [    0    82   193   132   282   647   313   404  8986    95    18  6719\n",
      "   1130]\n",
      " [    0    10    24    25    44    97    56    57  1471    16     5   994\n",
      "    189]]\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "y_pred = dt.predict(X_test)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y_test, y_pred)), \"\\n\"\n",
    "print metrics.classification_report(y_test, y_pred)\n",
    "print metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.416s\n",
      "Accuracy:0.780 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.96      0.85     43529\n",
      "          1       0.66      0.53      0.59       375\n",
      "          2       0.69      0.50      0.58      1006\n",
      "          3       0.71      0.50      0.58       745\n",
      "          4       0.67      0.47      0.55      1598\n",
      "          5       0.71      0.50      0.59      3539\n",
      "          6       0.74      0.48      0.58      1591\n",
      "          7       0.71      0.46      0.56      1978\n",
      "          8       0.78      0.86      0.82     87368\n",
      "          9       0.88      0.39      0.54       518\n",
      "         10       0.90      0.36      0.51       154\n",
      "         11       0.82      0.58      0.68     43375\n",
      "         12       0.96      0.36      0.52      7106\n",
      "\n",
      "avg / total       0.79      0.78      0.77    192882\n",
      "\n",
      "\n",
      "Confussion matrix\n",
      "[[41932     0     0     0     1     2     0     0  1312     0     0   280\n",
      "      2]\n",
      " [   30   198     0     0     0     1     0     1   100     0     0    44\n",
      "      1]\n",
      " [  104     1   499     0     0     1     0     0   317     0     0    82\n",
      "      2]\n",
      " [   76     1     5   369     1     0     0     1   200     0     0    90\n",
      "      2]\n",
      " [  142     5    12     3   758     3     0     1   499     0     0   171\n",
      "      4]\n",
      " [  276     5    12     9    14  1780     0     2  1094     0     0   344\n",
      "      3]\n",
      " [  129     3     7     2     6    15   761     1   485     0     0   181\n",
      "      1]\n",
      " [  165     5     8     2    12    22    11   902   665     0     0   182\n",
      "      4]\n",
      " [ 7770    34    83    62   165   332   115   163 75421     0     0  3182\n",
      "     41]\n",
      " [   44     0     4     2     5     4     5     6   194   200     0    54\n",
      "      0]\n",
      " [    7     0     3     0     1     4     2     0    71     0    55    11\n",
      "      0]\n",
      " [ 3560    38    73    59   140   278   108   158 13891    22     6 24999\n",
      "     43]\n",
      " [  542     8    22    10    35    62    23    34  2831     6     0   989\n",
      "   2544]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "dt.fit(X_train_fs, y_train)\n",
    "X_test_fs = fs.transform(X_test)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "measure_performance(X_train_fs, y_train, dt, show_accuracy=True, show_classification_true=True, show_confussion_matric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.060s\n",
      "Accuracy:0.572 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.89      0.79     18567\n",
      "          1       0.00      0.00      0.00       164\n",
      "          2       0.01      0.01      0.01       422\n",
      "          3       0.01      0.01      0.01       316\n",
      "          4       0.01      0.01      0.01       651\n",
      "          5       0.03      0.02      0.03      1484\n",
      "          6       0.02      0.01      0.01       733\n",
      "          7       0.02      0.01      0.01       857\n",
      "          8       0.62      0.69      0.65     37175\n",
      "          9       0.02      0.01      0.01       244\n",
      "         10       0.00      0.00      0.00        63\n",
      "         11       0.39      0.27      0.32     19001\n",
      "         12       0.06      0.03      0.04      2988\n",
      "\n",
      "avg / total       0.53      0.57      0.55     82665\n",
      "\n",
      "[[16449     3    18     7    11    49    24    18  1356     5     2   576\n",
      "     49]\n",
      " [   14     0     1     3     2     8     2     4    81     0     0    39\n",
      "     10]\n",
      " [   41     3     3     3     6    10     3     7   224     2     0   110\n",
      "     10]\n",
      " [   36     0     3     2     5     9     4     3   161     0     1    83\n",
      "      9]\n",
      " [   64     3     2     7     6    16    10    15   333     2     1   172\n",
      "     20]\n",
      " [  169     4     5     7    20    35    16    18   786     3     0   383\n",
      "     38]\n",
      " [   71     2     5     5     8    13     9     9   413     4     0   176\n",
      "     18]\n",
      " [   95     4     3     4    11    25     6    11   467     2     2   205\n",
      "     22]\n",
      " [ 3930    64   151   109   241   527   219   287 25567    48    19  5444\n",
      "    569]\n",
      " [   17     0     1     0     1     7     1     4   136     2     0    64\n",
      "     11]\n",
      " [   11     0     2     0     2     1     0     1    27     0     0    12\n",
      "      7]\n",
      " [ 2001    64   136    97   201   474   191   218  9944    40    20  5103\n",
      "    512]\n",
      " [  301    10    28    11    21    69    37    42  1638     4     7   735\n",
      "     85]]\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "y_pred_fs = dt.predict(X_test_fs)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y_test, y_pred_fs)), \"\\n\"\n",
    "print metrics.classification_report(y_test, y_pred_fs)\n",
    "print metrics.confusion_matrix(y_test, y_pred_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "Characteristics:\n",
    "* low bias\n",
    "* high variance\n",
    "* prone to overfitting\n",
    "\n",
    "Tuning Parameters:\n",
    "* number of trees\n",
    "* number of features to consider at each split\n",
    "* depth of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more features \n",
    "In order to see whether adding session data makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sessions\n",
    "sessions.rename(columns = {'user_id': 'id'}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
